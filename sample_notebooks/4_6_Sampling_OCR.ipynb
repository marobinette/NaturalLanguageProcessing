{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1 Samplig"
      ],
      "metadata": {
        "id": "gQ4ttiOnQfa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import random\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "d4iFTjQSQ1eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed so everyone gets the same results\n",
        "# This is important for reproducible research!\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "w2StvAlPQ5hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Building our text collection\n",
        "# in real research, you'd download these from Project Gutenberg or similar sources\n",
        "# Tip: inspect your sources before starting https://www.gutenberg.org/cache/epub/2701/pg2701.txt\n",
        "\n",
        "# Each text is a dictionary with metadata we care about\n",
        "# This structure helps us organize and filter our collection later\n",
        "texts = [\n",
        "    {\n",
        "        \"id\": \"pg2701\",                    # Unique identifier from source\n",
        "        \"title\": \"Moby Dick\",              # Human-readable title\n",
        "        \"author\": \"Herman Melville\",       # Author for filtering/grouping\n",
        "        \"year\": 1851,                      # Publication year\n",
        "        \"chapters\": [                      # The actual text content (simplified)\n",
        "            \"Call me Ishmael. Some years ago—never mind how long precisely...\",\n",
        "            \"The Carpet-Bag. I stuffed a shirt or two into my old carpet-bag...\",\n",
        "            \"The Spouter-Inn. Entering that gable-ended Spouter-Inn...\",\n",
        "            \"The Counterpane. Upon waking next morning about daylight...\"\n",
        "        ],\n",
        "        \"word_count\": 200000               # Metadata for analysis\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"pg1342\",\n",
        "        \"title\": \"Pride and Prejudice\",\n",
        "        \"author\": \"Jane Austen\",\n",
        "        \"year\": 1813,\n",
        "        \"chapters\": [\n",
        "            \"It is a truth universally acknowledged, that a single man...\",\n",
        "            \"When Jane and Elizabeth were alone, the former, who had been...\",\n",
        "            \"Not all that Mrs. Bennet, however, with the assistance of her...\"\n",
        "        ],\n",
        "        \"word_count\": 120000\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"pg11\",\n",
        "        \"title\": \"Alice in Wonderland\",\n",
        "        \"author\": \"Lewis Carroll\",\n",
        "        \"year\": 1865,\n",
        "        \"chapters\": [\n",
        "            \"Down the Rabbit-Hole. Alice was beginning to get very tired...\",\n",
        "            \"The Pool of Tears. 'Curiouser and curiouser!' cried Alice...\",\n",
        "            \"A Caucus-Race and a Long Tale. They were indeed a queer-looking party...\"\n",
        "        ],\n",
        "        \"word_count\": 27000\n",
        "    }\n",
        "]\n",
        "\n",
        "# Convert to pandas DataFrame - this makes data easier to work with\n",
        "# Think of it like an Excel spreadsheet you can manipulate with code\n",
        "df = pd.DataFrame(texts)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "89HfyZM6Q_hl",
        "outputId": "2edd6116-4d74-430d-ab18-66ade579da4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                title           author  year  \\\n",
              "0  pg2701            Moby Dick  Herman Melville  1851   \n",
              "1  pg1342  Pride and Prejudice      Jane Austen  1813   \n",
              "2    pg11  Alice in Wonderland    Lewis Carroll  1865   \n",
              "\n",
              "                                            chapters  word_count  \n",
              "0  [Call me Ishmael. Some years ago—never mind ho...      200000  \n",
              "1  [It is a truth universally acknowledged, that ...      120000  \n",
              "2  [Down the Rabbit-Hole. Alice was beginning to ...       27000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c534e933-fb99-439e-9c39-c81951086866\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>year</th>\n",
              "      <th>chapters</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pg2701</td>\n",
              "      <td>Moby Dick</td>\n",
              "      <td>Herman Melville</td>\n",
              "      <td>1851</td>\n",
              "      <td>[Call me Ishmael. Some years ago—never mind ho...</td>\n",
              "      <td>200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pg1342</td>\n",
              "      <td>Pride and Prejudice</td>\n",
              "      <td>Jane Austen</td>\n",
              "      <td>1813</td>\n",
              "      <td>[It is a truth universally acknowledged, that ...</td>\n",
              "      <td>120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pg11</td>\n",
              "      <td>Alice in Wonderland</td>\n",
              "      <td>Lewis Carroll</td>\n",
              "      <td>1865</td>\n",
              "      <td>[Down the Rabbit-Hole. Alice was beginning to ...</td>\n",
              "      <td>27000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c534e933-fb99-439e-9c39-c81951086866')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c534e933-fb99-439e-9c39-c81951086866 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c534e933-fb99-439e-9c39-c81951086866');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aeb32c1e-f357-4d0a-b81e-51b6aad92792\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aeb32c1e-f357-4d0a-b81e-51b6aad92792')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aeb32c1e-f357-4d0a-b81e-51b6aad92792 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e8fbd7c1-1cc5-410d-97cd-f0ea56c5be59\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e8fbd7c1-1cc5-410d-97cd-f0ea56c5be59 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"pg2701\",\n          \"pg1342\",\n          \"pg11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Moby Dick\",\n          \"Pride and Prejudice\",\n          \"Alice in Wonderland\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Herman Melville\",\n          \"Jane Austen\",\n          \"Lewis Carroll\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 1813,\n        \"max\": 1865,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1851,\n          1813,\n          1865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chapters\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86581,\n        \"min\": 27000,\n        \"max\": 200000,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          200000,\n          120000,\n          27000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Creating detailed inventory (manifest)\n",
        "# We need to 'flatten' our data - one row per chapter instead of per book\n",
        "# This gives us more sampling options later\n",
        "\n",
        "# Create a list to store all our chapter-level data\n",
        "chapters = []\n",
        "\n",
        "# Loop through each text in our collection\n",
        "for text in texts:\n",
        "    # For each text, loop through its chapters\n",
        "    for i, chapter_text in enumerate(text['chapters']):\n",
        "        # Create a new record for each chapter\n",
        "        chapter_record = {\n",
        "            'text_id': text['id'],                           # Which book this chapter comes from\n",
        "            'chapter_id': f\"{text['id']}_ch{i+1:02d}\",      # Unique ID for this specific chapter\n",
        "            'title': text['title'],                          # Book title (repeated for each chapter)\n",
        "            'author': text['author'],                        # Author (repeated for each chapter)\n",
        "            'chapter_num': i + 1,                           # Chapter number (1, 2, 3...)\n",
        "            'chapter_text': chapter_text,                    # The actual text content\n",
        "            'text_length': len(chapter_text)                # Length in characters\n",
        "        }\n",
        "        chapters.append(chapter_record)\n",
        "\n",
        "# Convert to DataFrame for easy manipulation\n",
        "chapter_df = pd.DataFrame(chapters)\n",
        "chapter_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "CRZDI5EtRPCk",
        "outputId": "1f7dac28-0f51-4014-efed-68471b64f55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  text_id   chapter_id                title           author  chapter_num  \\\n",
              "0  pg2701  pg2701_ch01            Moby Dick  Herman Melville            1   \n",
              "1  pg2701  pg2701_ch02            Moby Dick  Herman Melville            2   \n",
              "2  pg2701  pg2701_ch03            Moby Dick  Herman Melville            3   \n",
              "3  pg2701  pg2701_ch04            Moby Dick  Herman Melville            4   \n",
              "4  pg1342  pg1342_ch01  Pride and Prejudice      Jane Austen            1   \n",
              "5  pg1342  pg1342_ch02  Pride and Prejudice      Jane Austen            2   \n",
              "6  pg1342  pg1342_ch03  Pride and Prejudice      Jane Austen            3   \n",
              "7    pg11    pg11_ch01  Alice in Wonderland    Lewis Carroll            1   \n",
              "8    pg11    pg11_ch02  Alice in Wonderland    Lewis Carroll            2   \n",
              "9    pg11    pg11_ch03  Alice in Wonderland    Lewis Carroll            3   \n",
              "\n",
              "                                        chapter_text  text_length  \n",
              "0  Call me Ishmael. Some years ago—never mind how...           64  \n",
              "1  The Carpet-Bag. I stuffed a shirt or two into ...           66  \n",
              "2  The Spouter-Inn. Entering that gable-ended Spo...           57  \n",
              "3  The Counterpane. Upon waking next morning abou...           59  \n",
              "4  It is a truth universally acknowledged, that a...           60  \n",
              "5  When Jane and Elizabeth were alone, the former...           63  \n",
              "6  Not all that Mrs. Bennet, however, with the as...           64  \n",
              "7  Down the Rabbit-Hole. Alice was beginning to g...           62  \n",
              "8  The Pool of Tears. 'Curiouser and curiouser!' ...           60  \n",
              "9  A Caucus-Race and a Long Tale. They were indee...           72  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a7d8dbb-76b1-4e8f-80b3-319021a0bce9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>chapter_id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>chapter_num</th>\n",
              "      <th>chapter_text</th>\n",
              "      <th>text_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pg2701</td>\n",
              "      <td>pg2701_ch01</td>\n",
              "      <td>Moby Dick</td>\n",
              "      <td>Herman Melville</td>\n",
              "      <td>1</td>\n",
              "      <td>Call me Ishmael. Some years ago—never mind how...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pg2701</td>\n",
              "      <td>pg2701_ch02</td>\n",
              "      <td>Moby Dick</td>\n",
              "      <td>Herman Melville</td>\n",
              "      <td>2</td>\n",
              "      <td>The Carpet-Bag. I stuffed a shirt or two into ...</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pg2701</td>\n",
              "      <td>pg2701_ch03</td>\n",
              "      <td>Moby Dick</td>\n",
              "      <td>Herman Melville</td>\n",
              "      <td>3</td>\n",
              "      <td>The Spouter-Inn. Entering that gable-ended Spo...</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pg2701</td>\n",
              "      <td>pg2701_ch04</td>\n",
              "      <td>Moby Dick</td>\n",
              "      <td>Herman Melville</td>\n",
              "      <td>4</td>\n",
              "      <td>The Counterpane. Upon waking next morning abou...</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pg1342</td>\n",
              "      <td>pg1342_ch01</td>\n",
              "      <td>Pride and Prejudice</td>\n",
              "      <td>Jane Austen</td>\n",
              "      <td>1</td>\n",
              "      <td>It is a truth universally acknowledged, that a...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pg1342</td>\n",
              "      <td>pg1342_ch02</td>\n",
              "      <td>Pride and Prejudice</td>\n",
              "      <td>Jane Austen</td>\n",
              "      <td>2</td>\n",
              "      <td>When Jane and Elizabeth were alone, the former...</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pg1342</td>\n",
              "      <td>pg1342_ch03</td>\n",
              "      <td>Pride and Prejudice</td>\n",
              "      <td>Jane Austen</td>\n",
              "      <td>3</td>\n",
              "      <td>Not all that Mrs. Bennet, however, with the as...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>pg11</td>\n",
              "      <td>pg11_ch01</td>\n",
              "      <td>Alice in Wonderland</td>\n",
              "      <td>Lewis Carroll</td>\n",
              "      <td>1</td>\n",
              "      <td>Down the Rabbit-Hole. Alice was beginning to g...</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>pg11</td>\n",
              "      <td>pg11_ch02</td>\n",
              "      <td>Alice in Wonderland</td>\n",
              "      <td>Lewis Carroll</td>\n",
              "      <td>2</td>\n",
              "      <td>The Pool of Tears. 'Curiouser and curiouser!' ...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pg11</td>\n",
              "      <td>pg11_ch03</td>\n",
              "      <td>Alice in Wonderland</td>\n",
              "      <td>Lewis Carroll</td>\n",
              "      <td>3</td>\n",
              "      <td>A Caucus-Race and a Long Tale. They were indee...</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a7d8dbb-76b1-4e8f-80b3-319021a0bce9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a7d8dbb-76b1-4e8f-80b3-319021a0bce9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a7d8dbb-76b1-4e8f-80b3-319021a0bce9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5275a010-f470-4baa-bb87-87cb76ec871f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5275a010-f470-4baa-bb87-87cb76ec871f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5275a010-f470-4baa-bb87-87cb76ec871f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_cdd96983-22b1-40f5-b283-79dbbc818d91\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('chapter_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cdd96983-22b1-40f5-b283-79dbbc818d91 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('chapter_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "chapter_df",
              "summary": "{\n  \"name\": \"chapter_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"pg2701\",\n          \"pg1342\",\n          \"pg11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chapter_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"pg11_ch02\",\n          \"pg2701_ch02\",\n          \"pg1342_ch02\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Moby Dick\",\n          \"Pride and Prejudice\",\n          \"Alice in Wonderland\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Herman Melville\",\n          \"Jane Austen\",\n          \"Lewis Carroll\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chapter_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chapter_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"The Pool of Tears. 'Curiouser and curiouser!' cried Alice...\",\n          \"The Carpet-Bag. I stuffed a shirt or two into my old carpet-bag...\",\n          \"When Jane and Elizabeth were alone, the former, who had been...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 57,\n        \"max\": 72,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          66,\n          63,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Learning different sampling strategies\n",
        "# Each strategy answers different research questions\n",
        "\n",
        "def random_sample(items, n):\n",
        "    # random.sample() picks n items without replacement (no duplicates)\n",
        "    return random.sample(items, min(n, len(items)))"
      ],
      "metadata": {
        "id": "OoUG758YRe46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_sample(df, n_per_group, group_col='text_id'):\n",
        "    sampled_indices = []  # Keep track of which rows we selected\n",
        "\n",
        "    # Get all unique values in the grouping column\n",
        "    for group in df[group_col].unique():\n",
        "        # Filter to just this group's data\n",
        "        group_data = df[df[group_col] == group]\n",
        "\n",
        "        # Don't try to sample more than we have\n",
        "        n_sample = min(n_per_group, len(group_data))\n",
        "\n",
        "        # Randomly pick n_sample rows from this group\n",
        "        sample_indices = random.sample(list(group_data.index), n_sample)\n",
        "        sampled_indices.extend(sample_indices)\n",
        "\n",
        "    # Return the selected rows\n",
        "    return df.loc[sampled_indices]"
      ],
      "metadata": {
        "id": "UhakqS3RSn-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Trying out each sampling method\n",
        "# Let's see what each strategy actually gives us\n",
        "\n",
        "# Convert DataFrame to list of dictionaries for easier handling\n",
        "all_chapters = chapter_df.to_dict('records')\n",
        "print(f\"We have {len(all_chapters)} total chapters to sample from\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRTI1dncQzI1",
        "outputId": "c169784c-678d-4f52-afda-832e57b9b818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 10 total chapters to sample from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RANDOM SAMPLING: Pick 3 chapters at random\")\n",
        "print(\"=\"*60)\n",
        "random_chapters = random_sample(all_chapters, 3)\n",
        "print(\"Results:\")\n",
        "for i, ch in enumerate(random_chapters, 1):\n",
        "    print(f\"   {i}. {ch['title']} - Chapter {ch['chapter_num']}\")\n",
        "    print(f\"      Preview: {ch['chapter_text'][:50]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU16nByqS6Hy",
        "outputId": "d691ae43-00d5-4598-f3e3-09dd1af460bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RANDOM SAMPLING: Pick 3 chapters at random\n",
            "============================================================\n",
            "Results:\n",
            "   1. Moby Dick - Chapter 2\n",
            "      Preview: The Carpet-Bag. I stuffed a shirt or two into my o...\n",
            "   2. Alice in Wonderland - Chapter 2\n",
            "      Preview: The Pool of Tears. 'Curiouser and curiouser!' crie...\n",
            "   3. Alice in Wonderland - Chapter 3\n",
            "      Preview: A Caucus-Race and a Long Tale. They were indeed a ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STRATIFIED SAMPLING: 1 chapter from each book\")\n",
        "print(\"=\"*60)\n",
        "stratified_result = stratified_sample(chapter_df, 1)\n",
        "print(\"Results:\")\n",
        "for i, (_, row) in enumerate(stratified_result.iterrows(), 1):\n",
        "    print(f\"   {i}. {row['title']} - Chapter {row['chapter_num']}\")\n",
        "    print(f\"      Preview: {row['chapter_text'][:50]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwD4V7-yS3qP",
        "outputId": "44b062b6-b60e-49b8-90dd-41d96f4e8520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STRATIFIED SAMPLING: 1 chapter from each book\n",
            "============================================================\n",
            "Results:\n",
            "   1. Moby Dick - Chapter 4\n",
            "      Preview: The Counterpane. Upon waking next morning about da...\n",
            "   2. Pride and Prejudice - Chapter 1\n",
            "      Preview: It is a truth universally acknowledged, that a sin...\n",
            "   3. Alice in Wonderland - Chapter 1\n",
            "      Preview: Down the Rabbit-Hole. Alice was beginning to get v...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Saving your work (reproducibility!)\n",
        "# Create a folder for our output files\n",
        "output_dir = Path(\"samples\")\n",
        "output_dir.mkdir(exist_ok=True)  # Create folder if it doesn't exist\n",
        "\n",
        "# Save each sample to a CSV file\n",
        "# CSV = Comma Separated Values, readable by Excel, R, etc.\n",
        "\n",
        "# Convert our random sample back to a DataFrame and save\n",
        "random_df = pd.DataFrame(random_chapters)\n",
        "random_file = output_dir / \"random_sample.csv\"\n",
        "random_df.to_csv(random_file, index=False)  # index=False means don't save row numbers\n",
        "\n",
        "# Save systematic sample\n",
        "systematic_df = pd.DataFrame(systematic_chapters)\n",
        "systematic_file = output_dir / \"systematic_sample.csv\"\n",
        "systematic_df.to_csv(systematic_file, index=False)\n",
        "\n",
        "# Save stratified sample (already a DataFrame)\n",
        "stratified_file = output_dir / \"stratified_sample.csv\"\n",
        "stratified_result.to_csv(stratified_file, index=False)"
      ],
      "metadata": {
        "id": "2_QshietTLca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Analyzing our sampling results\n",
        "# Let's compare what each method gave us\n",
        "\n",
        "print(f\"\\n Sample sizes:\")\n",
        "print(f\" Random sample: {len(random_chapters)} chapters\")\n",
        "print(f\" Systematic sample: {len(systematic_chapters)} chapters\")\n",
        "print(f\" Stratified sample: {len(stratified_result)} chapters\")\n",
        "\n",
        "print(f\"\\n Author representation in random sample:\")\n",
        "# Count how many chapters each author got in our random sample\n",
        "random_df = pd.DataFrame(random_chapters)\n",
        "author_counts = random_df['author'].value_counts()\n",
        "print(author_counts)\n",
        "print(\"Notice: Random sampling might not give equal representation!\")\n",
        "\n",
        "print(f\"\\n Book representation in systematic sample:\")\n",
        "systematic_df = pd.DataFrame(systematic_chapters)\n",
        "book_counts = systematic_df['title'].value_counts()\n",
        "print(book_counts)\n",
        "print(\"Notice: Systematic sampling depends on how your data is ordered!\")\n",
        "\n",
        "print(f\"\\n Book representation in stratified sample:\")\n",
        "stratified_counts = stratified_result['title'].value_counts()\n",
        "print(stratified_counts)\n",
        "print(\"Notice: Stratified sampling guarantees equal representation!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsjyR87qTg42",
        "outputId": "bc71d03f-0cae-49f8-ddef-5c96a7874564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sample sizes:\n",
            " Random sample: 3 chapters\n",
            " Systematic sample: 5 chapters\n",
            " Stratified sample: 3 chapters\n",
            "\n",
            " Author representation in random sample:\n",
            "author\n",
            "Herman Melville    2\n",
            "Jane Austen        1\n",
            "Name: count, dtype: int64\n",
            "Notice: Random sampling might not give equal representation!\n",
            "\n",
            " Book representation in systematic sample:\n",
            "title\n",
            "Moby Dick              2\n",
            "Pride and Prejudice    2\n",
            "Alice in Wonderland    1\n",
            "Name: count, dtype: int64\n",
            "Notice: Systematic sampling depends on how your data is ordered!\n",
            "\n",
            " Book representation in stratified sample:\n",
            "title\n",
            "Moby Dick              1\n",
            "Pride and Prejudice    1\n",
            "Alice in Wonderland    1\n",
            "Name: count, dtype: int64\n",
            "Notice: Stratified sampling guarantees equal representation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunk chapters to be comparable units"
      ],
      "metadata": {
        "id": "xNDnFKSDUZyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "Ld8R-LNoUd2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_word_tokenize(text):\n",
        "    # Lightweight regex tokenizer: splits on word characters and keeps apostrophes inside words.\n",
        "    # words with optional internal apostrophes (e.g., don't, Ishmael's)\n",
        "    return re.findall(r\"[A-Za-z0-9]+(?:'[A-Za-z0-9]+)?\", text)\n"
      ],
      "metadata": {
        "id": "DUPlqrokU41r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_tokens(tokens, chunk_size=200, drop_last=True):\n",
        "    # Break a list of tokens into fixed-size chunks.\n",
        "    # - drop_last=True will discard the final short chunk so all chunks are exactly chunk_size long.\n",
        "    n_full = len(tokens) // chunk_size\n",
        "    end = n_full * chunk_size if drop_last else len(tokens)\n",
        "    return [tokens[i:i+chunk_size] for i in range(0, end, chunk_size)]\n"
      ],
      "metadata": {
        "id": "QBlRFLe8U_7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_chapters_equal_token_length(chapters_data, chunk_size=200, drop_last=True):\n",
        "    # Tokenize each chapter and split into fixed-size token chunks so all chunks are equal length.\n",
        "    # Returns a list of dicts with metadata for analysis or later modeling.\n",
        "    all_chunks = []\n",
        "    for chap_record in chapters_data:\n",
        "        chap_idx = chap_record['chapter_num']\n",
        "        chap_text = chap_record['chapter_text']\n",
        "        # Swap in nltk's word_tokenize(chap_text) if you prefer:\n",
        "        # tokens = word_tokenize(chap_text)\n",
        "        tokens = simple_word_tokenize(chap_text)\n",
        "        chunks = chunk_tokens(tokens, chunk_size=chunk_size, drop_last=drop_last)\n",
        "        for j, tok_chunk in enumerate(chunks):\n",
        "            all_chunks.append({\n",
        "                \"chapter_id\": chap_idx,\n",
        "                \"chunk_id\": j + 1,\n",
        "                \"token_count\": len(tok_chunk),  # will be == chunk_size if drop_last=True\n",
        "                \"text\": \" \".join(tok_chunk),\n",
        "                \"text_id\": chap_record['text_id'],\n",
        "                \"title\": chap_record['title'],\n",
        "                \"author\": chap_record['author'],\n",
        "                \"original_chapter_length\": chap_record['text_length']\n",
        "            })\n",
        "    return all_chunks"
      ],
      "metadata": {
        "id": "kMYKjakYUzMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Example usage with your Moby Dick chapters ----\n",
        "CHUNK_SIZE = 10  # set the common token length you want for all chunks\n",
        "moby_dick_chapters = [chap for chap in all_chapters if chap['title'] == 'Moby Dick']\n",
        "moby_chunks = chunk_chapters_equal_token_length(moby_dick_chapters, chunk_size=CHUNK_SIZE, drop_last=True)"
      ],
      "metadata": {
        "id": "babC_u9EVJpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional sanity checks / quick prints\n",
        "print(f\"Total chunks created: {len(moby_chunks)}\")\n",
        "print(\"First chunk metadata:\", {k:v for k,v in moby_chunks[0].items() if k!='text'})\n",
        "print(\"First 200-token chunk preview:\", moby_chunks[0][\"text\"][:300], \"...\")\n",
        "# You can convert to a DataFrame if you want tabular analysis:\n",
        "# import pandas as pd\n",
        "# moby_df = pd.DataFrame(moby_chunks)\n",
        "# moby_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFYM2brVVLen",
        "outputId": "47a54251-ec43-4d9b-aa63-d1e1637e0e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks created: 2\n",
            "First chunk metadata: {'chapter_id': 1, 'chunk_id': 1, 'token_count': 10, 'text_id': 'pg2701', 'title': 'Moby Dick', 'author': 'Herman Melville', 'original_chapter_length': 64}\n",
            "First 200-token chunk preview: Call me Ishmael Some years ago never mind how long ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2: Handling PDfs"
      ],
      "metadata": {
        "id": "ORmsoJVIVLTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0_hbs2ZD7wd",
        "outputId": "cb93e59b-a590-467f-f57f-885dfebbe550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "\n",
        "import pymupdf\n",
        "import re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "kK97hVf8sBsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Load and extract text from actual PDFs\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    print(f\"Opening PDF: {pdf_path}\")\n",
        "\n",
        "    try:\n",
        "        # Open the PDF document using PyMuPDF\n",
        "        doc = pymupdf.open(pdf_path)\n",
        "        pages_data = []\n",
        "\n",
        "        # Process each page in the document\n",
        "        for page_num in range(len(doc)):\n",
        "            # Load the current page\n",
        "            page = doc.load_page(page_num)\n",
        "\n",
        "            # Extract plain text from the page\n",
        "            text = page.get_text()\n",
        "\n",
        "            # Create page data dictionary with text and statistics\n",
        "            page_data = {\n",
        "                'page': page_num + 1,           # Convert to 1-indexed page number\n",
        "                'text': text,                   # Raw extracted text\n",
        "                'char_count': len(text),        # Total character count including whitespace\n",
        "                'word_count': len(text.split()) # Simple word count by splitting on whitespace\n",
        "            }\n",
        "\n",
        "            pages_data.append(page_data)\n",
        "\n",
        "            # Log progress for current page\n",
        "            print(f\"   Page {page_num + 1}: {len(text)} characters, {len(text.split())} words\")\n",
        "\n",
        "        # Clean up: close the document to free memory\n",
        "        doc.close()\n",
        "\n",
        "        # Log successful completion\n",
        "        print(f\"✓ Successfully extracted {len(pages_data)} pages\")\n",
        "        return pages_data\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"✗ Error: PDF file not found at path: {pdf_path}\")\n",
        "        return None\n",
        "    except PermissionError:\n",
        "        print(f\"✗ Error: Permission denied when trying to read: {pdf_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error reading PDF: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "wRXuMLGlu338"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_text_preview(text, title, max_chars=300):\n",
        "    print(f\"\\n {title} Preview:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Truncate text and remove line breaks for clean display\n",
        "    preview = text[:max_chars].replace('\\n', ' ')\n",
        "    print(f\"{preview}...\")\n",
        "\n",
        "    # Show total character count\n",
        "    print(f\"Total length: {len(text)} characters\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "q4Zbiz_T8su-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PDFs (adjust paths as needed)\n",
        "# UVM Electrical Engineering document\n",
        "uvm_pdf_path = \"/content/electricalengineering.pdf\"  # Your academic catalog\n",
        "try:\n",
        "    uvm_pages = extract_text_from_pdf(uvm_pdf_path)\n",
        "    if uvm_pages:\n",
        "        uvm_text = \"\\n\".join([page['text'] for page in uvm_pages])\n",
        "        show_text_preview(uvm_text, \"UVM Electrical Engineering Catalog\")\n",
        "except:\n",
        "    print(f\" Could not load {uvm_pdf_path} - make sure file exists in current directory\")\n",
        "    uvm_text = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KiDbGMPsSvP",
        "outputId": "c1de60ba-0c14-407e-954e-aa3537646efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening PDF: /content/electricalengineering.pdf\n",
            "   Page 1: 5145 characters, 667 words\n",
            "✓ Successfully extracted 1 pages\n",
            "\n",
            " UVM Electrical Engineering Catalog Preview:\n",
            "--------------------------------------------------\n",
            "THE UNIVERSITY OF VERMONT ELECTRICAL ENGINEERING ELECTRICAL ENGINEERING http://www.uvm.edu/~cems/soe/ OVERVIEW The Electrical Engineering (EE) program at the University of Vermont is at the forefront of research in the areas of digital signal processing, control systems, power and energy systems, wi...\n",
            "Total length: 5145 characters\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Analyze what PyMuPDF extracted\n",
        "\n",
        "# Let's see what issues PyMuPDF extraction reveals...\n",
        "\n",
        "def analyze_extraction_quality(text, doc_name):\n",
        "    if not text:\n",
        "        print(f\" No text to analyze for {doc_name}\")\n",
        "        return None\n",
        "\n",
        "    issues = {}\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Issue 1: Empty or very short lines (formatting artifacts)\n",
        "    empty_lines = [line for line in lines if len(line.strip()) == 0]\n",
        "    short_lines = [line for line in lines if 0 < len(line.strip()) < 3]\n",
        "    issues['empty_lines'] = len(empty_lines)\n",
        "    issues['short_lines'] = len(short_lines)\n",
        "\n",
        "    # Issue 2: Lines that are all uppercase (likely headers)\n",
        "    uppercase_lines = [line for line in lines if line.isupper() and len(line.strip()) > 3]\n",
        "    issues['uppercase_lines'] = len(uppercase_lines)\n",
        "\n",
        "    # Issue 3: Lines with mostly numbers (dates, page numbers, etc.)\n",
        "    number_heavy_lines = [line for line in lines if\n",
        "                         len(re.findall(r'\\d', line)) / max(len(line), 1) > 0.3\n",
        "                         and len(line.strip()) > 2]\n",
        "    issues['number_heavy_lines'] = len(number_heavy_lines)\n",
        "\n",
        "    # Issue 4: Potential OCR errors (mixed numbers and letters)\n",
        "    mixed_chars = re.findall(r'\\w*\\d[A-Za-z]\\w*|\\w*[A-Za-z]\\d\\w*', text)\n",
        "    issues['mixed_chars'] = len(set(mixed_chars))  # Unique instances\n",
        "\n",
        "    # Issue 5: Very long lines (might be unwrapped text)\n",
        "    long_lines = [line for line in lines if len(line) > 200]\n",
        "    issues['very_long_lines'] = len(long_lines)\n",
        "\n",
        "    print(f\"\\n {doc_name} Extraction Analysis:\")\n",
        "    for issue, count in issues.items():\n",
        "        print(f\"   • {issue.replace('_', ' ').title()}: {count}\")\n",
        "\n",
        "    # Show actual examples of problematic content\n",
        "    print(f\"\\n Examples of issues found in {doc_name}:\")\n",
        "\n",
        "    if short_lines:\n",
        "        print(f\"  Short lines (first 5):\")\n",
        "        for i, line in enumerate(short_lines[:5]):\n",
        "            print(f\"      {i+1}. '{line.strip()}'\")\n",
        "\n",
        "    if uppercase_lines:\n",
        "        print(f\"  Uppercase lines (first 3):\")\n",
        "        for i, line in enumerate(uppercase_lines[:3]):\n",
        "            print(f\"      {i+1}. '{line.strip()}'\")\n",
        "\n",
        "    if number_heavy_lines:\n",
        "        print(f\" Number-heavy lines (first 3):\")\n",
        "        for i, line in enumerate(number_heavy_lines[:3]):\n",
        "            print(f\"      {i+1}. '{line.strip()}'\")\n",
        "\n",
        "    if mixed_chars:\n",
        "        print(f\" Mixed character words (first 5):\")\n",
        "        unique_mixed = list(set(mixed_chars))[:5]\n",
        "        for i, word in enumerate(unique_mixed):\n",
        "            print(f\"      {i+1}. '{word}'\")\n",
        "\n",
        "    if long_lines:\n",
        "        print(f\"  Very long lines (first 2, truncated):\")\n",
        "        for i, line in enumerate(long_lines[:2]):\n",
        "            truncated = line.strip()[:100] + \"...\" if len(line.strip()) > 100 else line.strip()\n",
        "            print(f\"      {i+1}. '{truncated}'\")\n",
        "\n",
        "    # Store the actual problematic content for further inspection\n",
        "    issues_with_content = {\n",
        "        'empty_lines': empty_lines,\n",
        "        'short_lines': short_lines,\n",
        "        'uppercase_lines': uppercase_lines,\n",
        "        'number_heavy_lines': number_heavy_lines,\n",
        "        'mixed_chars': mixed_chars,\n",
        "        'long_lines': long_lines\n",
        "    }\n",
        "\n",
        "    return issues, issues_with_content\n"
      ],
      "metadata": {
        "id": "j4BXR3rtVPW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze both documents if they loaded\n",
        "if uvm_text:\n",
        "    uvm_issues, uvm_content = analyze_extraction_quality(uvm_text, \"UVM Document\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUgsEFRf80hr",
        "outputId": "da3e509d-0d0a-4079-9a82-c07e6eeea711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " UVM Document Extraction Analysis:\n",
            "   • Empty Lines: 1\n",
            "   • Short Lines: 1\n",
            "   • Uppercase Lines: 9\n",
            "   • Number Heavy Lines: 3\n",
            "   • Mixed Chars: 0\n",
            "   • Very Long Lines: 0\n",
            "\n",
            " Examples of issues found in UVM Document:\n",
            "  Short lines (first 5):\n",
            "      1. '1'\n",
            "  Uppercase lines (first 3):\n",
            "      1. 'THE UNIVERSITY OF VERMONT'\n",
            "      2. 'ELECTRICAL ENGINEERING'\n",
            "      3. 'ELECTRICAL ENGINEERING'\n",
            " Number-heavy lines (first 3):\n",
            "      1. 'CS 5220.'\n",
            "      2. 'EE 5410.'\n",
            "      3. 'EE 5610, CS 5610.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep dive into specific issues\n",
        "if uvm_text and 'uvm_content' in locals():\n",
        "    print(\"\\n DETAILED INSPECTION:\")\n",
        "\n",
        "    # Look at all upper case lines\n",
        "    if uvm_content['uppercase_lines']:\n",
        "        print(f\"\\n upper case lines:\")\n",
        "        for line in uvm_content['uppercase_lines']:\n",
        "            print(f\"   '{line.strip()}'\")"
      ],
      "metadata": {
        "id": "6LtwZ-Rg_Qhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3740aae3-6c40-4ae8-f650-a07de84eccf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DETAILED INSPECTION:\n",
            "\n",
            " upper case lines:\n",
            "   'THE UNIVERSITY OF VERMONT'\n",
            "   'ELECTRICAL ENGINEERING'\n",
            "   'ELECTRICAL ENGINEERING'\n",
            "   'OVERVIEW'\n",
            "   'DEGREES'\n",
            "   'FACULTY'\n",
            "   'CS 5220.'\n",
            "   'EE 5410.'\n",
            "   'EE 5610, CS 5610.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Advanced PyMuPDF extraction with layout info\n",
        "# PyMuPDF can give us much more than just text...we can also get information about layout\n",
        "# Layout can give us a lot of clues about text which can help pull out desired data\n",
        "\n",
        "def extract_with_layout(pdf_path, page_num=0):\n",
        "    try:\n",
        "        doc = pymupdf.open(pdf_path)\n",
        "        page = doc.load_page(page_num)\n",
        "\n",
        "        # Extract text with detailed formatting as dictionary structure\n",
        "        blocks = page.get_text(\"dict\")\n",
        "\n",
        "        formatted_elements = []\n",
        "\n",
        "        # Navigate the hierarchical structure: blocks -> lines -> spans\n",
        "        for block in blocks[\"blocks\"]:\n",
        "            if \"lines\" in block:  # Skip image blocks, process only text blocks\n",
        "                for line in block[\"lines\"]:\n",
        "                    for span in line[\"spans\"]:\n",
        "                        # Create element with text content and formatting metadata\n",
        "                        element = {\n",
        "                            'text': span['text'],\n",
        "                            'bbox': span['bbox'],    # Bounding box coordinates\n",
        "                            'font': span['font'],    # Font family name\n",
        "                            'size': span['size'],    # Font size in points\n",
        "                            'flags': span['flags']   # Style flags (bold=16, italic=2, etc.)\n",
        "                        }\n",
        "                        formatted_elements.append(element)\n",
        "\n",
        "        doc.close()\n",
        "        return formatted_elements\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error extracting layout: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "_tny66CH6MBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_document_structure(elements):\n",
        "    if not elements:\n",
        "        return\n",
        "\n",
        "    # Group by font size to identify headers\n",
        "    font_sizes = [elem['size'] for elem in elements]\n",
        "    size_counts = Counter(font_sizes)\n",
        "\n",
        "    print(\" Font size distribution:\")\n",
        "    for size, count in sorted(size_counts.items(), reverse=True):\n",
        "        print(f\"   Size {size:.1f}: {count} elements\")\n",
        "\n",
        "    # Find likely headers (larger font sizes)\n",
        "    avg_size = sum(font_sizes) / len(font_sizes)\n",
        "    headers = [elem for elem in elements if elem['size'] > avg_size * 1.2]\n",
        "\n",
        "    print(f\"\\n Likely headers ({len(headers)} found):\")\n",
        "    for header in headers[:5]:  # Show first 5\n",
        "        text_preview = header['text'][:50].replace('\\n', ' ')\n",
        "        print(f\"   '{text_preview}' (size: {header['size']:.1f})\")\n",
        "\n",
        "    # Identify fonts used\n",
        "    fonts = set(elem['font'] for elem in elements)\n",
        "    print(f\"\\n Fonts detected: {len(fonts)}\")\n",
        "    for font in sorted(fonts)[:5]:  # Show first 5\n",
        "        print(f\"   {font}\")"
      ],
      "metadata": {
        "id": "jmAG5lE36X-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try advanced extraction on first document\n",
        "if uvm_text:\n",
        "    print(\"Analyzing UVM document structure...\")\n",
        "    uvm_layout = extract_with_layout(uvm_pdf_path, 0)\n",
        "    if uvm_layout:\n",
        "        analyze_document_structure(uvm_layout)\n"
      ],
      "metadata": {
        "id": "RQzGZ01C6aJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee332465-1731-4ae7-e68e-0574655c3cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing UVM document structure...\n",
            " Font size distribution:\n",
            "   Size 14.0: 1 elements\n",
            "   Size 12.0: 5 elements\n",
            "   Size 10.0: 103 elements\n",
            "   Size 8.0: 1 elements\n",
            "\n",
            " Likely headers (1 found):\n",
            "   'ELECTRICAL ENGINEERING' (size: 14.0)\n",
            "\n",
            " Fonts detected: 4\n",
            "   ArnoPro-Bold\n",
            "   ArnoPro-Regular\n",
            "   MyriadPro-Regular\n",
            "   MyriadPro-SemiboldSemiEx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Smart text cleaning based on document type\n",
        "\n",
        "def detect_document_type(text):\n",
        "    if not text:\n",
        "        return \"unknown\"\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Academic document indicators\n",
        "    academic_keywords = ['university', 'course', 'credit', 'prerequisite', 'professor', 'department']\n",
        "    academic_score = sum(1 for keyword in academic_keywords if keyword in text_lower)\n",
        "\n",
        "    # Legal document indicators\n",
        "    legal_keywords = ['county', 'state of', 'notary', 'acknowledged', 'sworn', 'witness']\n",
        "    legal_score = sum(1 for keyword in legal_keywords if keyword in text_lower)\n",
        "\n",
        "    if academic_score > legal_score:\n",
        "        return \"academic\"\n",
        "    elif legal_score > academic_score:\n",
        "        return \"legal\"\n",
        "    else:\n",
        "        return \"general\"\n",
        "\n"
      ],
      "metadata": {
        "id": "rJ1NBhYR6l7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_academic_document(text):\n",
        "    print(\" Applying academic document cleaning...\")\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://[^\\s]+', '[URL]', text)\n",
        "\n",
        "    # Standardize course codes (CMPE 5220. -> CMPE 5220:)\n",
        "    text = re.sub(r'([A-Z]{2,4}\\s+\\d{4})\\.\\s*', r'\\1: ', text)\n",
        "\n",
        "    # Clean up credit formatting\n",
        "    text = re.sub(r'(\\d+)\\s+Credits?\\.\\s*', r'\\1 Credits. ', text)\n",
        "\n",
        "    # Fix broken faculty names (often split across lines)\n",
        "    # \"Smith, John; Professor\" format\n",
        "    text = re.sub(r'([A-Z][a-z]+),\\s*([A-Z][a-z]+);\\s*', r'\\1, \\2; ', text)\n",
        "\n",
        "    # Remove excessive whitespace but preserve structure\n",
        "    text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)\n",
        "    text = re.sub(r' +', ' ', text)\n",
        "\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "jnoq7xjB6yrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_legal_document(text):\n",
        "    print(\" Applying legal document cleaning...\")\n",
        "\n",
        "    # Standardize legal formatting\n",
        "    text = re.sub(r'STATE\\s+OF\\s+([A-Z]+)\\s*\\)', r'STATE OF \\1)', text)\n",
        "    text = re.sub(r'\\)\\s*\\n\\s*\\)\\s*ss:', r')\\n) ss:', text)\n",
        "\n",
        "    # Fix date formatting\n",
        "    text = re.sub(r'(\\d{1,2})\\w*\\s+day\\s+of\\s+([A-Z][a-z]+)\\s*,?\\s*(\\d{4})',\n",
        "                  r'\\1 day of \\2, \\3', text)\n",
        "\n",
        "    # Clean up signature formatting\n",
        "    text = re.sub(r'\\[Signature\\]', '[SIGNATURE]', text)\n",
        "\n",
        "    # Fix page references\n",
        "    text = re.sub(r'Page\\s+(\\d+)\\s+of\\s+(\\d+)', r'Page \\1 of \\2', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "3TFLDkJy6tWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply document-specific cleaning\n",
        "documents_to_clean = []\n",
        "\n",
        "if uvm_text:\n",
        "    uvm_type = detect_document_type(uvm_text)\n",
        "    print(f\"\\nUVM document detected as: {uvm_type}\")\n",
        "\n",
        "    if uvm_type == \"academic\":\n",
        "        cleaned_uvm = clean_academic_document(uvm_text)\n",
        "    else:\n",
        "        cleaned_uvm = uvm_text\n",
        "\n",
        "    documents_to_clean.append((\"UVM\", uvm_text, cleaned_uvm))\n",
        "\n"
      ],
      "metadata": {
        "id": "m_k2lJOW6tZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6647d4-240b-465b-d801-bc15713ee4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UVM document detected as: academic\n",
            " Applying academic document cleaning...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WARNING: In this section I am showing areas where you can add errors in by the cleaning choices you make. The point is be thoughtful about generalizing one error you find in one space to the entire document."
      ],
      "metadata": {
        "id": "gqhATmuaA6y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: OCR error detection and correction or is this error inducing?\n",
        "\n",
        "#what is wrong with this approach?\n",
        "\n",
        "def find_ocr_errors(text):\n",
        "    errors = {}\n",
        "\n",
        "    # Common OCR character confusions\n",
        "    char_errors = []\n",
        "    char_errors.extend(re.findall(r'\\bl[A-Z]', text))  # l instead of I\n",
        "    char_errors.extend(re.findall(r'\\b0[A-Za-z]', text))  # 0 instead of O\n",
        "    char_errors.extend(re.findall(r'rn([a-z])', text))  # rn instead of m\n",
        "    errors['character_substitutions'] = len(char_errors)\n",
        "\n",
        "    # Broken words (space in middle)\n",
        "    broken_words = re.findall(r'\\b[A-Za-z]{1,2}\\s+[a-z]{2,}\\b', text)\n",
        "    errors['broken_words'] = len(broken_words)\n",
        "\n",
        "    # Numbers in words where they shouldn't be\n",
        "    number_in_words = re.findall(r'[A-Za-z]+\\d+[A-Za-z]*|\\d+[A-Za-z]+', text)\n",
        "    # Filter out valid cases like \"5220\" or \"2011\"\n",
        "    suspicious_numbers = [w for w in number_in_words if not w.isdigit()]\n",
        "    errors['numbers_in_words'] = len(suspicious_numbers)\n",
        "\n",
        "    return errors, char_errors, broken_words, suspicious_numbers"
      ],
      "metadata": {
        "id": "5wL12j127FbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_ocr_errors(text):\n",
        "    print(\" Fixing OCR errors...\")\n",
        "\n",
        "    # Character substitution fixes\n",
        "    fixes = [\n",
        "        # Protect common abbreviations first\n",
        "        (r'\\bPHD\\b', 'PhD'),\n",
        "        (r'\\bDSC\\b', 'DSc'),\n",
        "\n",
        "        # Fix l/I confusion (careful with word boundaries)\n",
        "        (r'\\bl([A-Z][a-z])', r'I\\1'),\n",
        "\n",
        "        # Fix 0/O confusion\n",
        "        (r'\\b0([A-Za-z])', r'O\\1'),\n",
        "        (r'([a-z])0\\b', r'\\1o'),\n",
        "\n",
        "        # Fix rn/m confusion\n",
        "        (r'rn([a-z])', r'm\\1'),\n",
        "        (r'([a-z])rn\\b', r'\\1m'),\n",
        "\n",
        "        # Fix obvious broken words\n",
        "        (r'\\bU niversity\\b', 'University'),\n",
        "        (r'\\bE ngineering\\b', 'Engineering'),\n",
        "        (r'\\bD epartment\\b', 'Department'),\n",
        "    ]\n",
        "\n",
        "    for pattern, replacement in fixes:\n",
        "        before_count = len(re.findall(pattern, text))\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "        after_count = len(re.findall(pattern, text))\n",
        "        if before_count > 0:\n",
        "            print(f\"   Fixed {before_count} instances of '{pattern}' pattern\")\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "XUNP1Tic7RwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply OCR fixes to cleaned documents\n",
        "for doc_name, original, cleaned in documents_to_clean:\n",
        "    print(f\"\\n Processing {doc_name} document...\")\n",
        "\n",
        "    # Find errors in cleaned version\n",
        "    errors, char_errs, broken, suspicious = find_ocr_errors(cleaned)\n",
        "\n",
        "    print(f\"Errors found in {doc_name}:\")\n",
        "    for error_type, count in errors.items():\n",
        "        print(f\"   • {error_type.replace('_', ' ').title()}: {count}\")\n",
        "\n",
        "    if char_errs:\n",
        "        print(f\"   Character errors examples: {char_errs[:3]}\")\n",
        "    if suspicious:\n",
        "        print(f\"   Suspicious words: {suspicious[:3]}\")\n",
        "\n",
        "    # Apply fixes\n",
        "    fixed_text = fix_ocr_errors(cleaned)\n",
        "\n",
        "    # Update our document list with fixed version\n",
        "    if doc_name == \"UVM\":\n",
        "        fixed_uvm = fixed_text"
      ],
      "metadata": {
        "id": "csaUyj1q7VOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b0ad02-4a6d-4f12-880f-03b80a12caf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Processing UVM document...\n",
            "Errors found in UVM:\n",
            "   • Character Substitutions: 3\n",
            "   • Broken Words: 39\n",
            "   • Numbers In Words: 0\n",
            "   Character errors examples: ['e', 's', 'i']\n",
            " Fixing OCR errors...\n",
            "   Fixed 10 instances of '\\bPHD\\b' pattern\n",
            "   Fixed 1 instances of '\\bDSC\\b' pattern\n",
            "   Fixed 3 instances of 'rn([a-z])' pattern\n",
            "   Fixed 1 instances of '([a-z])rn\\b' pattern\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Quality assessment and comparison\n",
        "\n",
        "\n",
        "def compare_versions(original, cleaned, fixed, doc_name):\n",
        "\n",
        "    print(f\"\\n {doc_name} Processing Results:\")\n",
        "    print(f\"   Original length: {len(original)} characters\")\n",
        "    print(f\"   After cleaning:  {len(cleaned)} characters ({len(cleaned)-len(original):+d})\")\n",
        "    print(f\"   After OCR fixes: {len(fixed)} characters ({len(fixed)-len(cleaned):+d})\")\n",
        "\n",
        "    # Count remaining potential issues\n",
        "    remaining_errors, _, _, _ = find_ocr_errors(fixed)\n",
        "    total_remaining = sum(remaining_errors.values())\n",
        "    print(f\"   Remaining potential errors: {total_remaining}\")\n",
        "\n",
        "    return {\n",
        "        'original_len': len(original),\n",
        "        'cleaned_len': len(cleaned),\n",
        "        'fixed_len': len(fixed),\n",
        "        'remaining_errors': total_remaining\n",
        "    }"
      ],
      "metadata": {
        "id": "CX8cQKTl7k6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare all versions\n",
        "results = {}\n",
        "for doc_name, original, cleaned in documents_to_clean:\n",
        "    if doc_name == \"UVM\" and 'fixed_uvm' in locals():\n",
        "        results[doc_name] = compare_versions(original, cleaned, fixed_uvm, doc_name)"
      ],
      "metadata": {
        "id": "dVt5Ji5V7qXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Save processed documents\n",
        "\n",
        "# Create output directory\n",
        "output_dir = Path(\"processed_pdfs\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "saved_files = []\n",
        "\n",
        "# Save processed documents\n",
        "if 'fixed_uvm' in locals():\n",
        "    uvm_output = output_dir / \"uvm_electrical_engineering_processed.txt\"\n",
        "    with open(uvm_output, 'w', encoding='utf-8') as f:\n",
        "        f.write(fixed_uvm)\n",
        "    saved_files.append(uvm_output)\n",
        "    print(f\" Saved: {uvm_output}\")\n",
        "\n",
        "# Save processing summary\n",
        "summary_data = []\n",
        "for doc_name, stats in results.items():\n",
        "    summary_data.append({\n",
        "        'document': doc_name,\n",
        "        'original_length': stats['original_len'],\n",
        "        'final_length': stats['fixed_len'],\n",
        "        'change': stats['fixed_len'] - stats['original_len'],\n",
        "        'remaining_errors': stats['remaining_errors']\n",
        "    })\n",
        "\n",
        "if summary_data:\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_file = output_dir / \"processing_summary.csv\"\n",
        "    summary_df.to_csv(summary_file, index=False)\n",
        "    print(f\" Saved processing summary: {summary_file}\")\n"
      ],
      "metadata": {
        "id": "9jEm6fzJ72OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OCR Example 2: PDF to PNG and comparing OCR tools"
      ],
      "metadata": {
        "id": "kjMlV681B7qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "rcCjeV6DCZgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4116e15c-0194-43b7-e328-f5775c2f51a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (11.3.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import\n",
        "\n",
        "import pymupdf\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from pathlib import Path\n",
        "import io"
      ],
      "metadata": {
        "id": "cAS4JS3FCWx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: When do you need PDF to PNG conversion?\n",
        "print(\"\\n STEP 1: When do you need PDF → PNG conversion?\")\n",
        "print(\"You need this when:\")\n",
        "print(\"   1. PDF has NO extractable text (scanned documents)\")\n",
        "print(\"   2. PyMuPDF extracts gibberish or empty text\")\n",
        "print(\"   3. Document is an image embedded in PDF\")\n",
        "print(\"   4. You want better OCR quality than embedded text\")"
      ],
      "metadata": {
        "id": "3QyLfa72EscC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e21d5b8-ab14-403a-a082-01ef52190ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " STEP 1: When do you need PDF → PNG conversion?\n",
            "You need this when:\n",
            "   1. PDF has NO extractable text (scanned documents)\n",
            "   2. PyMuPDF extracts gibberish or empty text\n",
            "   3. Document is an image embedded in PDF\n",
            "   4. You want better OCR quality than embedded text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Check if PDF has extractable text\n",
        "\n",
        "def check_pdf_text_extractable(pdf_path):\n",
        "    try:\n",
        "        doc = pymupdf.open(pdf_path)\n",
        "        page = doc.load_page(0)  # Check first page\n",
        "        text = page.get_text().strip()\n",
        "        doc.close()\n",
        "\n",
        "        if len(text) > 50:  # Arbitrary threshold\n",
        "            print(f\" PDF has extractable text ({len(text)} characters)\")\n",
        "            print(f\"   Preview: '{text[:100]}...'\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\" PDF has little/no extractable text ({len(text)} characters)\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error checking PDF: {e}\")\n",
        "        return False\n",
        "\n",
        "# Test with your PDF\n",
        "pdf_path = \"/content/electricalengineering.pdf\"  # Your scanned/image PDF\n",
        "\n",
        "print(f\"\\n Checking {pdf_path}...\")\n",
        "has_text = check_pdf_text_extractable(pdf_path)\n",
        "\n",
        "if has_text:\n",
        "    print(\"   → You probably DON'T need PNG conversion\")\n",
        "else:\n",
        "    print(\"   → You NEED PNG conversion for OCR\")"
      ],
      "metadata": {
        "id": "aX25dAPjE7Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9ccd1e-6ff2-4fd3-803e-86bca6b6ca65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Checking /content/electricalengineering.pdf...\n",
            " Error checking PDF: no such file: '/content/electricalengineering.pdf'\n",
            "   → You NEED PNG conversion for OCR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Convert PDF page to PNG\n",
        "\n",
        "def pdf_page_to_png(pdf_path, page_num=0, dpi=300):\n",
        "\n",
        "    try:\n",
        "        # Open PDF\n",
        "        doc = pymupdf.open(pdf_path)\n",
        "        page = doc.load_page(page_num)\n",
        "\n",
        "        # Convert to image\n",
        "        # Higher DPI = better quality but larger file\n",
        "        mat = pymupdf.Matrix(dpi/72, dpi/72)  # 72 is default DPI\n",
        "        pix = page.get_pixmap(matrix=mat)\n",
        "\n",
        "        # Convert to PIL Image\n",
        "        img_data = pix.tobytes(\"png\")\n",
        "        img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "        doc.close()\n",
        "\n",
        "        print(f\" Converted page {page_num} to {img.size[0]}x{img.size[1]} PNG\")\n",
        "        return img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error converting PDF: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "BmPcjSnkFmBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_png(img, output_path):\n",
        "#Save PIL image as PNG file\n",
        "    img.save(output_path, \"PNG\")\n",
        "    print(f\" Saved PNG: {output_path}\")\n",
        "\n",
        "# Convert first page to PNG\n",
        "print(\"Converting PDF page to PNG...\")\n",
        "\n",
        "# Note: In live demo, make sure you have a scanned PDF to use\n",
        "try:\n",
        "    # Convert page to image\n",
        "    img = pdf_page_to_png(pdf_path, page_num=0, dpi=300)\n",
        "\n",
        "    if img:\n",
        "        # Save the PNG\n",
        "        png_path = \"page_0.png\"\n",
        "        save_png(img, png_path)\n",
        "\n",
        "        print(f\" Image dimensions: {img.size[0]} x {img.size[1]} pixels\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Could not convert PDF (make sure {pdf_path} exists)\")\n",
        "    print(\"For demo purposes, we'll simulate having a PNG image...\")\n",
        "    png_path = \"sample_page.png\"  # You'd have this from conversion\n"
      ],
      "metadata": {
        "id": "ec4Gyk4oFqXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: OCR the PNG with Tesseract\n",
        "\n",
        "def ocr_image_with_tesseract(image_path):\n",
        "\n",
        "    try:\n",
        "        # Load image\n",
        "        img = Image.open(image_path)\n",
        "\n",
        "        # Run OCR with different configurations\n",
        "        # Default OCR\n",
        "        text_default = pytesseract.image_to_string(img)\n",
        "\n",
        "        # OCR with better configuration for documents\n",
        "        custom_config = r'--oem 3 --psm 6'  # OCR Engine Mode 3, Page Segmentation Mode 6\n",
        "        text_custom = pytesseract.image_to_string(img, config=custom_config)\n",
        "\n",
        "        print(f\" OCR completed\")\n",
        "        print(f\"   Default config: {len(text_default)} characters\")\n",
        "        print(f\"   Custom config:  {len(text_custom)} characters\")\n",
        "\n",
        "        # Return the better result\n",
        "        return text_custom if len(text_custom) > len(text_default) else text_default\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" OCR error: {e}\")\n",
        "        print(\"   Make sure Tesseract is installed: apt-get install tesseract-ocr\")\n",
        "        return None\n",
        "\n",
        "# Run OCR on the PNG\n",
        "print(\"Running Tesseract OCR on PNG...\")\n",
        "\n",
        "try:\n",
        "    ocr_text = ocr_image_with_tesseract(png_path)\n",
        "\n",
        "    if ocr_text:\n",
        "        print(f\"\\n OCR Results:\")\n",
        "        print(f\"   Length: {len(ocr_text)} characters\")\n",
        "        print(f\"   Preview: '{ocr_text[:200]}...'\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Could not run OCR: {e}\")\n",
        "    print(\"For demo, here's what OCR might extract:\")\n",
        "\n"
      ],
      "metadata": {
        "id": "n-YZEwPqGHBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Compare methods and when to use each\n",
        "\n",
        "print(\"\\n STEP 5: Comparing extraction methods\")\n",
        "\n",
        "def compare_extraction_methods(pdf_path):\n",
        "    \"\"\"\n",
        "    Compare direct PDF text extraction vs OCR\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Method 1: Direct PDF extraction\n",
        "    try:\n",
        "        doc = pymupdf.open(pdf_path)\n",
        "        direct_text = doc[0].get_text()\n",
        "        doc.close()\n",
        "        results['direct'] = {\n",
        "            'text': direct_text,\n",
        "            'length': len(direct_text),\n",
        "            'method': 'PyMuPDF direct extraction'\n",
        "        }\n",
        "    except:\n",
        "        results['direct'] = {\n",
        "            'text': '',\n",
        "            'length': 0,\n",
        "            'method': 'PyMuPDF direct extraction (failed)'\n",
        "        }\n",
        "\n",
        "    # Method 2: OCR (we already have this)\n",
        "    results['ocr'] = {\n",
        "        'text': ocr_text,\n",
        "        'length': len(ocr_text) if ocr_text else 0,\n",
        "        'method': 'Tesseract OCR on PNG'\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Compare methods\n",
        "print(\"Comparing extraction methods...\")\n",
        "\n",
        "try:\n",
        "    comparison = compare_extraction_methods(pdf_path)\n",
        "\n",
        "    print(f\"\\n Method Comparison:\")\n",
        "    for method, data in comparison.items():\n",
        "        print(f\"   {data['method']}:\")\n",
        "        print(f\"      Length: {data['length']} characters\")\n",
        "        if data['length'] > 0:\n",
        "            preview = data['text'][:100].replace('\\n', ' ')\n",
        "            print(f\"      Preview: '{preview}...'\")\n",
        "        else:\n",
        "            print(f\"      Result: No text extracted\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Could not compare methods: {e}\")"
      ],
      "metadata": {
        "id": "ibLinpEbGYWu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}